# template for loading custom attributes
output_file:   # where to save compiled data; accepted extensions are .csv and .parquet
  - data/TEST_CUSTOM_OUT1.parquet
file_id_subsets: # a .csv with a single column listing which gauges to keep (must match id_columns in files_in)
    - data/tests/custom_attribute_data/id_subset.csv
# TODO: add ability to read in a list of gage_ids to use/keep
# file_io defines the name of each file holding attributes of interest, and specifies column names of interest for each file
# accepted file extensions include csv, txt, xlsx, xlsm
files_in: # May define {home_dir} for python's '{home_dir}/string_path'.format(home_dir =str(Path.home())) functionality
  C:/Projects/NOAA_NWM/Data/CAMELS/camels_clim.txt:
    separator: # tries ',', ';', ' ', '\t' if not provided for txt file
      - ;
    id_column:
      - gauge_id
    attr_columns:
      - p_mean
      - pet_mean
      - p_seasonality
      - frac_snow
      - aridity
      - high_prec_freq
      - high_prec_dur
      - high_prec_timing
      - low_prec_freq
      - low_prec_dur
      - low_prec_timing
  C:/Projects/NOAA_NWM/Data/CAMELS/camels_geol.txt:
    id_column:
      - gauge_id
    attr_columns:
      - geol_1st_class
      - glim_1st_class_frac
      - geol_2nd_class
      - glim_2nd_class_frac
      - carbonate_rocks_frac
      - geol_porostiy
      - geol_permeability
  C:/Projects/NOAA_NWM/Data/GAGESii/basinchar_and_report_sept_2011/gagesII_sept30_2011_conterm.xlsx:
    tabs:
      BasinID:
        id_column:
          - STAID
        attr_columns:
          - DRAIN_SQKM
          - HUC02
          - LAT_GAGE
          - LNG_GAGE
          - STATE
          - BOUND_SOURCE
          - HCDN-2009 
          - HBN36
      Bas_Classif:
        id_column:
          - STAID
        attr_columns:
          - CLASS
          - AGGECOREGION
      Climate:
        id_column:
          - STAID
        attr_columns:
          - PPTAVG_BASIN
          - T_AVG_SITE




  # - 'path_data': 'C:/Projects/NOAA_NWM/Regionalization/FSDS/TOPMODEL_CFE_Calibration_BChoat/NWM_performance_14.csv' # Where the raw input data are stored.
  # - 'dir_save': 'C:/Projects/NOAA_NWM/Regionalization/FSDS/StandardizedData' # Required. The save location of standardized output
  # - 'save_type': 'csv' #  Required. Use 'csv' to create a directory structure & save multiple files. May also save as hierarchical files 'netcdf' or 'zarr', or if 'csv' chosen, a directory structure is created
  # - 'save_loc': 'local' #  Required.  Use 'local' for saving to a local path via dir_save. Future work will create an approach for 'aws' or other cloud saving methods
attribute_metadata:  
  - 'dataset_name': 'ngenBEC' # Required. 
  - 'formulation_base': 'CFE' # Required. Basename of formulation. the rr, sp, and gw will be added to this if 'formulation_id' is left empty
  - 'formulation_id': 'CFE' # Optional alternative in lieu of generating a formulation_id based on 'formulation_base'. Should leave empty if automatic formulation_id generation desired.
  - 'formulation_ver': # Optional. The version of the formulation
  - 'temporal_res': 'hourly' # The temporal resolution corresponding to the modeled data
  - 'target_var': 'Q' # Required. The target variable modeled. This is standardized. See target_var_mappings in fsds_categories.yaml
  - 'start_date': '2008-10-01' # Required. The YYYY-MM-DD start date corresponding to the evaluation metric's modeled timeseries
  - 'end_date':  '2013-10-01' # Required. The YYYY-MM-DD end date corresponding to the evaluation metric's modeled timeseries
  - 'modeled notes': 'PET module used was one that best predicted aridity index as calculated based on gridded weather data. Runoff partitioned using Schaake.'
  - 'cal_status': 'Y' # Required. Was the formulation model fully calibrated? Options include 'Y','N', or 'S' (yes/no/somewhat)
  - 'start_date_cal': '2008-10-01' # The YYYY-MM-DD start date corresponding to the calibration period
  - 'end_date_cal': '2013-10-01' # The YYYY-MM-DD end date corresponding to the calibration period
  - 'cal_notes': 'DDS algorithm in ngen-cal framework was used.'
references: # All optional but **very** helpful metadata
  - 'input_filepath': '{base_dir}/FSDS/temp_data/raw/TOPMODEL_CFE_Calibration_BChoat/ReadMe.txt'
  - 'source_url': 'NA'
  - 'dataset_doi': 'NA'
  - 'literature_doi': 'NA'
